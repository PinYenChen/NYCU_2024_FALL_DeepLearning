{"cells":[{"cell_type":"markdown","metadata":{"id":"86CvAQ3yMIZk"},"source":["# Just an example.You can alter sample code anywhere."]},{"cell_type":"markdown","metadata":{"id":"GrXIBH51THl_"},"source":["## mount your google drive"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18706,"status":"ok","timestamp":1726555709784,"user":{"displayName":"Pin-Yen Chen","userId":"12629589973337489947"},"user_tz":-480},"id":"sx47B97qMNwv","outputId":"c6879047-a86d-4ae4-8a3b-881d1e84c55a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["\n","from google.colab import drive\n","drive.mount('/content/drive')\n"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":340,"status":"ok","timestamp":1726555731269,"user":{"displayName":"Pin-Yen Chen","userId":"12629589973337489947"},"user_tz":-480},"id":"erMgvx83MUrm","outputId":"bb410a37-8408-4f56-95f9-938ceab781df"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/DL_Lab1\n"]}],"source":["\n","# You need to modify this part to the directory where your code is located\n","%cd \"/content/drive/MyDrive/DL_Lab1\"\n"]},{"cell_type":"markdown","metadata":{"id":"C9OZRaZETbZT"},"source":["## Import packages\n"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":1891,"status":"ok","timestamp":1726555827612,"user":{"displayName":"Pin-Yen Chen","userId":"12629589973337489947"},"user_tz":-480},"id":"fv1K7EfGMIZm","scrolled":true},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import model"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":327,"status":"ok","timestamp":1726555829399,"user":{"displayName":"Pin-Yen Chen","userId":"12629589973337489947"},"user_tz":-480},"id":"qr3ieyG9MIZn"},"outputs":[],"source":["#Fix the random seed\n","np.random.seed(0)"]},{"cell_type":"markdown","metadata":{"id":"huwyyDbJMIZn"},"source":["## Load the data and label"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5975,"status":"ok","timestamp":1726555837956,"user":{"displayName":"Pin-Yen Chen","userId":"12629589973337489947"},"user_tz":-480},"id":"aahu3NcTMIZn","outputId":"5da90158-8bb8-4f96-b316-23451c281159"},"outputs":[{"output_type":"stream","name":"stdout","text":["shape of train_data: (60000, 784)\n","shape of train_label: (60000,)\n","shape of test_data: (10000, 784)\n"]}],"source":["train_load = np.loadtxt('./data/kmnist-train.csv',delimiter=',',dtype=\"int\")\n","test_load = np.loadtxt('./data/kmnist-test.csv',delimiter=',',dtype=\"int\")\n","\n","train_data=train_load[:,1:]\n","train_label=train_load[:,0]\n","test_data=test_load\n","print(\"shape of train_data: {}\".format(train_data.shape))\n","print(\"shape of train_label: {}\".format(train_label.shape))\n","print(\"shape of test_data: {}\".format(test_data.shape))"]},{"cell_type":"markdown","metadata":{"id":"RaauK7iDMIZo"},"source":["## Show the training data"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":358,"status":"ok","timestamp":1726555839647,"user":{"displayName":"Pin-Yen Chen","userId":"12629589973337489947"},"user_tz":-480},"id":"4ljhOuNKMIZo","scrolled":true},"outputs":[],"source":["#uncomment if you want to show the training data\n","#plt.figure(figsize=(20, 20))\n","#for index in range(10):\n","#    image = train_data[index+1000].reshape(28,28)\n","#    plt.subplot(2, 5, index+1)\n","#    plt.imshow(image)\n","#plt.show()"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":378,"status":"ok","timestamp":1726555841864,"user":{"displayName":"Pin-Yen Chen","userId":"12629589973337489947"},"user_tz":-480},"id":"ll-Mmg5uMIZo","outputId":"c92f8562-4813-415b-e59f-76f3d256ec1e"},"outputs":[{"output_type":"stream","name":"stdout","text":["train_image_num  is : 60000\n","test_image_num   is : 10000\n"]}],"source":["train_image_num = train_data.shape[0]\n","test_image_num = test_data.shape[0]\n","train_data = train_data.astype(np.float32)\n","test_data = test_data.astype(np.float32)\n","\n","print(\"train_image_num  is : {}\".format(train_image_num))\n","print(\"test_image_num   is : {}\".format(test_image_num))"]},{"cell_type":"markdown","metadata":{"id":"Lba_hUSCid9_"},"source":["## Validation image number"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":339,"status":"ok","timestamp":1726555844276,"user":{"displayName":"Pin-Yen Chen","userId":"12629589973337489947"},"user_tz":-480},"id":"ft6nsKeqMIZo"},"outputs":[],"source":["val_image_num=10000"]},{"cell_type":"markdown","metadata":{"id":"mEK-1W3SMIZo"},"source":["## Convert the training labels to one hot vector"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":331,"status":"ok","timestamp":1726555846061,"user":{"displayName":"Pin-Yen Chen","userId":"12629589973337489947"},"user_tz":-480},"id":"E5dbUzj3MIZp","outputId":"dcd6b522-b3e8-4ae6-c50e-4c3f9f5a7deb"},"outputs":[{"output_type":"stream","name":"stdout","text":["One-hot training labels shape: (60000, 10)\n"]}],"source":["label_temp = np.zeros((train_image_num, 10), dtype = np.float32)\n","for i in range(train_image_num):\n","    label_temp[i][train_label[i]] = 1\n","train_label_onehot = np.copy(label_temp)\n","print(\"One-hot training labels shape:\",train_label_onehot.shape)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"WgDMf7cUMIZp"},"source":["## Hyperparameters"]},{"cell_type":"code","execution_count":29,"metadata":{"executionInfo":{"elapsed":718,"status":"ok","timestamp":1726563585366,"user":{"displayName":"Pin-Yen Chen","userId":"12629589973337489947"},"user_tz":-480},"id":"WDROhN4WMIZp"},"outputs":[],"source":["EPOCH = 75\n","Batch_size = 500 # 10000 should be divisible by batch_size\n","Learning_rate = 0.001"]},{"cell_type":"markdown","metadata":{"id":"j9Eii_nPMIZp"},"source":["## Training"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":306513,"status":"ok","timestamp":1726563892901,"user":{"displayName":"Pin-Yen Chen","userId":"12629589973337489947"},"user_tz":-480},"id":"IBixF53yMIZp","outputId":"a0807a4f-779e-47ce-8975-4461236b2110"},"outputs":[{"output_type":"stream","name":"stdout","text":["Task1  | Epoch:  1  |Train Loss:  2.3014  |Train Acc:14.2780  |Val Loss:  2.2997  |Val Acc:17.3700\n","Task1  | Epoch:  2  |Train Loss:  2.2981  |Train Acc:20.1980  |Val Loss:  2.2960  |Val Acc:22.7300\n","Task1  | Epoch:  3  |Train Loss:  2.2938  |Train Acc:24.1580  |Val Loss:  2.2908  |Val Acc:25.1200\n","Task1  | Epoch:  4  |Train Loss:  2.2876  |Train Acc:25.4340  |Val Loss:  2.2828  |Val Acc:26.4600\n","Task1  | Epoch:  5  |Train Loss:  2.2773  |Train Acc:26.5280  |Val Loss:  2.2688  |Val Acc:28.0700\n","Task1  | Epoch:  6  |Train Loss:  2.2580  |Train Acc:28.6020  |Val Loss:  2.2411  |Val Acc:30.5600\n","Task1  | Epoch:  7  |Train Loss:  2.2166  |Train Acc:31.9440  |Val Loss:  2.1776  |Val Acc:34.9500\n","Task1  | Epoch:  8  |Train Loss:  2.1156  |Train Acc:35.8040  |Val Loss:  2.0239  |Val Acc:36.9400\n","Task1  | Epoch:  9  |Train Loss:  1.9253  |Train Acc:36.5760  |Val Loss:  1.8119  |Val Acc:38.7300\n","Task1  | Epoch: 10  |Train Loss:  1.7263  |Train Acc:42.2640  |Val Loss:  1.6222  |Val Acc:48.4400\n","Task1  | Epoch: 11  |Train Loss:  1.5522  |Train Acc:50.7300  |Val Loss:  1.4661  |Val Acc:54.1000\n","Task1  | Epoch: 12  |Train Loss:  1.4138  |Train Acc:55.2540  |Val Loss:  1.3414  |Val Acc:57.9000\n","Task1  | Epoch: 13  |Train Loss:  1.2933  |Train Acc:59.1320  |Val Loss:  1.2223  |Val Acc:61.7800\n","Task1  | Epoch: 14  |Train Loss:  1.1760  |Train Acc:63.3540  |Val Loss:  1.1070  |Val Acc:66.2400\n","Task1  | Epoch: 15  |Train Loss:  1.0708  |Train Acc:67.1160  |Val Loss:  1.0119  |Val Acc:69.7200\n","Task1  | Epoch: 16  |Train Loss:  0.9892  |Train Acc:69.7920  |Val Loss:  0.9413  |Val Acc:72.0900\n","Task1  | Epoch: 17  |Train Loss:  0.9278  |Train Acc:71.8120  |Val Loss:  0.8871  |Val Acc:73.7200\n","Task1  | Epoch: 18  |Train Loss:  0.8788  |Train Acc:73.3740  |Val Loss:  0.8427  |Val Acc:75.0500\n","Task1  | Epoch: 19  |Train Loss:  0.8376  |Train Acc:74.6140  |Val Loss:  0.8050  |Val Acc:75.9700\n","Task1  | Epoch: 20  |Train Loss:  0.8022  |Train Acc:75.6360  |Val Loss:  0.7727  |Val Acc:76.9900\n","Task1  | Epoch: 21  |Train Loss:  0.7713  |Train Acc:76.5580  |Val Loss:  0.7446  |Val Acc:77.5300\n","Task1  | Epoch: 22  |Train Loss:  0.7439  |Train Acc:77.2980  |Val Loss:  0.7198  |Val Acc:77.9800\n","Task1  | Epoch: 23  |Train Loss:  0.7191  |Train Acc:77.9260  |Val Loss:  0.6974  |Val Acc:78.6500\n","Task1  | Epoch: 24  |Train Loss:  0.6963  |Train Acc:78.4940  |Val Loss:  0.6768  |Val Acc:79.1600\n","Task1  | Epoch: 25  |Train Loss:  0.6750  |Train Acc:79.0320  |Val Loss:  0.6576  |Val Acc:79.5100\n","Task1  | Epoch: 26  |Train Loss:  0.6549  |Train Acc:79.6040  |Val Loss:  0.6395  |Val Acc:80.0500\n","Task1  | Epoch: 27  |Train Loss:  0.6358  |Train Acc:80.1320  |Val Loss:  0.6223  |Val Acc:80.5100\n","Task1  | Epoch: 28  |Train Loss:  0.6177  |Train Acc:80.6760  |Val Loss:  0.6059  |Val Acc:81.0900\n","Task1  | Epoch: 29  |Train Loss:  0.6003  |Train Acc:81.3140  |Val Loss:  0.5901  |Val Acc:81.6700\n","Task1  | Epoch: 30  |Train Loss:  0.5837  |Train Acc:81.8780  |Val Loss:  0.5750  |Val Acc:82.2500\n","Task1  | Epoch: 31  |Train Loss:  0.5677  |Train Acc:82.4360  |Val Loss:  0.5606  |Val Acc:82.6700\n","Task1  | Epoch: 32  |Train Loss:  0.5524  |Train Acc:82.9780  |Val Loss:  0.5468  |Val Acc:83.2000\n","Task1  | Epoch: 33  |Train Loss:  0.5376  |Train Acc:83.5020  |Val Loss:  0.5335  |Val Acc:83.5900\n","Task1  | Epoch: 34  |Train Loss:  0.5235  |Train Acc:83.9320  |Val Loss:  0.5210  |Val Acc:83.9500\n","Task1  | Epoch: 35  |Train Loss:  0.5100  |Train Acc:84.3600  |Val Loss:  0.5090  |Val Acc:84.4400\n","Task1  | Epoch: 36  |Train Loss:  0.4971  |Train Acc:84.7900  |Val Loss:  0.4977  |Val Acc:84.7800\n","Task1  | Epoch: 37  |Train Loss:  0.4848  |Train Acc:85.2260  |Val Loss:  0.4869  |Val Acc:85.1700\n","Task1  | Epoch: 38  |Train Loss:  0.4729  |Train Acc:85.6440  |Val Loss:  0.4765  |Val Acc:85.4600\n","Task1  | Epoch: 39  |Train Loss:  0.4616  |Train Acc:86.0100  |Val Loss:  0.4667  |Val Acc:85.9400\n","Task1  | Epoch: 40  |Train Loss:  0.4507  |Train Acc:86.3360  |Val Loss:  0.4574  |Val Acc:86.2200\n","Task1  | Epoch: 41  |Train Loss:  0.4402  |Train Acc:86.6860  |Val Loss:  0.4484  |Val Acc:86.4300\n","Task1  | Epoch: 42  |Train Loss:  0.4301  |Train Acc:87.0120  |Val Loss:  0.4398  |Val Acc:86.8000\n","Task1  | Epoch: 43  |Train Loss:  0.4204  |Train Acc:87.4080  |Val Loss:  0.4315  |Val Acc:87.0400\n","Task1  | Epoch: 44  |Train Loss:  0.4111  |Train Acc:87.7700  |Val Loss:  0.4237  |Val Acc:87.2500\n","Task1  | Epoch: 45  |Train Loss:  0.4021  |Train Acc:88.0060  |Val Loss:  0.4161  |Val Acc:87.4000\n","Task1  | Epoch: 46  |Train Loss:  0.3935  |Train Acc:88.2500  |Val Loss:  0.4088  |Val Acc:87.6500\n","Task1  | Epoch: 47  |Train Loss:  0.3852  |Train Acc:88.5300  |Val Loss:  0.4018  |Val Acc:87.7700\n","Task1  | Epoch: 48  |Train Loss:  0.3772  |Train Acc:88.7760  |Val Loss:  0.3951  |Val Acc:87.9800\n","Task1  | Epoch: 49  |Train Loss:  0.3695  |Train Acc:89.0020  |Val Loss:  0.3887  |Val Acc:88.1500\n","Task1  | Epoch: 50  |Train Loss:  0.3622  |Train Acc:89.2460  |Val Loss:  0.3824  |Val Acc:88.2300\n","Task1  | Epoch: 51  |Train Loss:  0.3551  |Train Acc:89.4400  |Val Loss:  0.3765  |Val Acc:88.3700\n","Task1  | Epoch: 52  |Train Loss:  0.3482  |Train Acc:89.6360  |Val Loss:  0.3707  |Val Acc:88.6100\n","Task1  | Epoch: 53  |Train Loss:  0.3416  |Train Acc:89.8300  |Val Loss:  0.3651  |Val Acc:88.8100\n","Task1  | Epoch: 54  |Train Loss:  0.3352  |Train Acc:90.0020  |Val Loss:  0.3598  |Val Acc:89.0100\n","Task1  | Epoch: 55  |Train Loss:  0.3291  |Train Acc:90.2060  |Val Loss:  0.3547  |Val Acc:89.1900\n","Task1  | Epoch: 56  |Train Loss:  0.3231  |Train Acc:90.4080  |Val Loss:  0.3497  |Val Acc:89.4000\n","Task1  | Epoch: 57  |Train Loss:  0.3174  |Train Acc:90.5960  |Val Loss:  0.3449  |Val Acc:89.5800\n","Task1  | Epoch: 58  |Train Loss:  0.3118  |Train Acc:90.7580  |Val Loss:  0.3403  |Val Acc:89.7700\n","Task1  | Epoch: 59  |Train Loss:  0.3063  |Train Acc:90.9280  |Val Loss:  0.3359  |Val Acc:89.9300\n","Task1  | Epoch: 60  |Train Loss:  0.3010  |Train Acc:91.0960  |Val Loss:  0.3316  |Val Acc:90.0900\n","Task1  | Epoch: 61  |Train Loss:  0.2959  |Train Acc:91.2520  |Val Loss:  0.3275  |Val Acc:90.2200\n","Task1  | Epoch: 62  |Train Loss:  0.2909  |Train Acc:91.4300  |Val Loss:  0.3235  |Val Acc:90.3900\n","Task1  | Epoch: 63  |Train Loss:  0.2860  |Train Acc:91.5620  |Val Loss:  0.3197  |Val Acc:90.5200\n","Task1  | Epoch: 64  |Train Loss:  0.2813  |Train Acc:91.7400  |Val Loss:  0.3160  |Val Acc:90.6800\n","Task1  | Epoch: 65  |Train Loss:  0.2766  |Train Acc:91.9340  |Val Loss:  0.3124  |Val Acc:90.7500\n","Task1  | Epoch: 66  |Train Loss:  0.2721  |Train Acc:92.0640  |Val Loss:  0.3089  |Val Acc:90.8600\n","Task1  | Epoch: 67  |Train Loss:  0.2677  |Train Acc:92.1920  |Val Loss:  0.3056  |Val Acc:90.9500\n","Task1  | Epoch: 68  |Train Loss:  0.2633  |Train Acc:92.3000  |Val Loss:  0.3024  |Val Acc:91.0800\n","Task1  | Epoch: 69  |Train Loss:  0.2591  |Train Acc:92.4540  |Val Loss:  0.2992  |Val Acc:91.2200\n","Task1  | Epoch: 70  |Train Loss:  0.2549  |Train Acc:92.5940  |Val Loss:  0.2961  |Val Acc:91.3400\n","Task1  | Epoch: 71  |Train Loss:  0.2508  |Train Acc:92.7580  |Val Loss:  0.2932  |Val Acc:91.4600\n","Task1  | Epoch: 72  |Train Loss:  0.2468  |Train Acc:92.8780  |Val Loss:  0.2904  |Val Acc:91.5600\n","Task1  | Epoch: 73  |Train Loss:  0.2429  |Train Acc:92.9860  |Val Loss:  0.2876  |Val Acc:91.6900\n","Task1  | Epoch: 74  |Train Loss:  0.2391  |Train Acc:93.1060  |Val Loss:  0.2848  |Val Acc:91.8000\n","Task1  | Epoch: 75  |Train Loss:  0.2353  |Train Acc:93.2200  |Val Loss:  0.2822  |Val Acc:91.8200\n"]}],"source":["# please make sure you have place layer.py & network.py in 'model' folder\n","net = model.Network()\n","\n","train_batch_num = (train_image_num  -  val_image_num  )//Batch_size\n","val_batch_num = (val_image_num)//Batch_size\n","\n","for epoch in range(1, EPOCH+1):\n","    train_hit = 0\n","    val_hit = 0\n","    total_train_loss = 0.0\n","    total_val_loss = 0.0\n","\n","\n","\n","    for it in range(train_batch_num):\n","        pred, train_loss = net.forward(train_data[it*Batch_size:(it+1)*Batch_size], train_label_onehot[it*Batch_size:(it+1)*Batch_size])\n","        pred_index = np.argmax(pred, axis=1)\n","        train_hit += (pred_index==train_label[it*Batch_size:(it+1)*Batch_size]).sum()\n","        total_train_loss += train_loss\n","\n","        net.backward()\n","        net.update(Learning_rate)\n","\n","    for titt in range(val_batch_num):\n","        tit=train_batch_num+titt\n","        pred, val_loss = net.forward(train_data[tit*Batch_size:(tit+1)*Batch_size], train_label_onehot[tit*Batch_size:(tit+1)*Batch_size])\n","        pred_index = np.argmax(pred, axis=1)\n","        val_hit += (pred_index==train_label[tit*Batch_size:(tit+1)*Batch_size]).sum()\n","        total_val_loss += val_loss\n","\n","    print('Task1  | Epoch:%3d'%epoch, ' |Train Loss:%8.4f'%(total_train_loss/train_batch_num), ' |Train Acc:%3.4f'%(train_hit/(train_image_num-val_image_num)*100.0)\n","          , ' |Val Loss:%8.4f'%(total_val_loss/val_batch_num), ' |Val Acc:%3.4f'%(val_hit/val_image_num*100.0))"]},{"cell_type":"markdown","metadata":{"id":"Ly3GmOtZMIZp"},"source":["## Dump for evaluation (upload your DL-test-predict.csv to kaggle )"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":1753,"status":"ok","timestamp":1726558114811,"user":{"displayName":"Pin-Yen Chen","userId":"12629589973337489947"},"user_tz":-480},"id":"adxtvK__MIZq","colab":{"base_uri":"https://localhost:8080/"},"outputId":"21e6d609-c7c0-4274-aabd-929db38ab83a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Please make sure that total test images = 10000\n","Total test images: 10000 \n","Dump file...\n"]}],"source":["test_pred_list = []\n","total_test = 0\n","for tit in range(test_image_num//Batch_size):\n","    pred, _ = net.forward(test_data[tit*Batch_size:(tit+1)*Batch_size], train_label_onehot[tit*Batch_size:(tit+1)*Batch_size])\n","    pred_index = np.argmax(pred, axis=1)\n","    test_pred_list += pred_index.tolist()\n","    total_test += Batch_size\n","\n","print('Please make sure that total test images = 10000')\n","print(f'Total test images: {total_test} ')\n","\n","print('Dump file...')\n","df = pd.DataFrame(test_pred_list, columns=[\"Category\"])\n","df.to_csv('DL-test-predict.csv', index=True, index_label=\"Id\")"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"tf_2.5_py3.7","language":"python","name":"tf_2.5_py3.7"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}